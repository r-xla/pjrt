
# pjrt

<!-- badges: start -->

[![Lifecycle:
experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
![R-CMD-check](https://github.com/r-xla/pjrt/actions/workflows/R-CMD-check.yaml/badge.svg)
[![CRAN
status](https://www.r-pkg.org/badges/version/pjrt)](https://CRAN.R-project.org/package=pjrt)
[![codecov](https://codecov.io/gh/r-xla/pjrt/branch/main/graph/badge.svg)](https://codecov.io/gh/r-xla/pjrt)
<!-- badges: end -->

The {pjrt} package provides an R interface to
[PJRT](https://github.com/openxla/pjrt) (Pretty much Just another
RunTime), which allows you to *run* [XLA](https://openxla.org/) and
[stableHLO](https://openxla.org/stablehlo) programs on various hardware
backends. These programs are framework and hardware agnostic, which
means they can be generated by ML frameworks such as jax, and run by
PJRT on a specified backend (CPU, GPU, etc.). For a low-level R
interface to *create* stableHLO programs, see the
[stablehlo](https://github.com/r-xla/stablehlo) package.

## Installation

``` r
pak::pak("r-xla/pjrt")
```

## Quickstart

Below, we create and run a stableHLO program that adds two f32 tensors
of shape (2, 2).

``` r
library(pjrt)
src <- r"(
func.func @main(
  %x: tensor<2x2xf32>,
  %y: tensor<2x2xf32>
) -> tensor<2x2xf32> {
  %0 = "stablehlo.add"(%x, %y) : (tensor<2x2xf32>, tensor<2x2xf32>) -> tensor<2x2xf32>
  "func.return"(%0): (tensor<2x2xf32>) -> ()
}
)"
program <- pjrt_program(src, format = "mlir")
program
#> PJRTProgram(format=mlir, code_size=221)
#> 
#> func.func @main(
#>   %x: tensor<2x2xf32>,
#>   %y: tensor<2x2xf32>
#> ) -> tensor<2x2xf32> {
#> ...
executable <- pjrt_compile(program, client = "cpu")

x <- pjrt_buffer(as.double(1:4), shape = c(2, 2), dtype = "f32")
x
#> PJRTBuffer<f32: 2x2> 
#>  1.0000 3.0000
#>  2.0000 4.0000
y <- pjrt_buffer(as.double(5:8), shape = c(2, 2), dtype = "f32")
y
#> PJRTBuffer<f32: 2x2> 
#>  5.0000 7.0000
#>  6.0000 8.0000

pjrt_execute(executable, x, y)
#> PJRTBuffer<f32: 2x2> 
#>   6.0000 10.0000
#>   8.0000 12.0000
```

## Main Features

- Compile stableHLO programs into hardware-specific executables.
- Provide a runtime to execute compiled programs.
- Convert buffers to and from R arrays and vectors.
- Read and write buffers using the
  [safetensors](https://github.com/mlverse/safetensors) format.

## Platform Support

- **Linux**
  - :white_check_mark: CPU backend is fully supported.
  - :white_check_mark: CUDA (NVIDIA GPU) backend is fully supported.
- **Windows**
  - :white_check_mark: CPU backend is fully supported.
  - :warning: GPU is only supported via Windows Subsystem for Linux
    (WSL2).
- **macOS**
  - :white_check_mark: CPU backend is supported.
  - :warning: Metal (Apple GPU) backend is available but not fully
    functional.

## Acknowledgements

- Without [OpenXLA](https://openxla.org/), none of this would be
  possible.
- The development of this package is supported by
  [MaRDI](https://www.mardi4nfdi.de/about/mission).
- The design of the {pjrt} package was inspired by the
  [gopjrt](https://github.com/gomlx/gopjrt) implementation.
- The project also uses various components from OpenXLA:
  - [PJRT C
    API](https://github.com/openxla/xla/blob/main/xla/pjrt/c/pjrt_c_api.h).
  - [PJRT C API FFI
    Extension](https://github.com/openxla/xla/blob/main/xla/pjrt/c/pjrt_c_api_ffi_extension.h).
  - Various protobuf files, see `./tools/copy-proto.R` for which ones.
  - Plugin implementations for CPU and CUDA (we are using the builds
    from [zml/pjrt-artifacts](https://github.com/zml/pjrt-artifacts/)).
- For Metal, we are using the plugin implementation from
  [jax-metal](https://pypi.org/project/jax-metal/).
