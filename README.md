
<!-- README.md is generated from README.Rmd. Please edit that file -->

# pjrt

<!-- badges: start -->

[![Lifecycle:
experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
![R-CMD-check](https://github.com/r-xla/pjrt/actions/workflows/R-CMD-check.yaml/badge.svg)
[![CRAN
status](https://www.r-pkg.org/badges/version/pjrt)](https://CRAN.R-project.org/package=pjrt)
[![codecov](https://codecov.io/gh/r-xla/pjrt/branch/main/graph/badge.svg)](https://codecov.io/gh/r-xla/pjrt)
<!-- badges: end -->

The {pjrt} package provides an R interface to
[PJRT](https://github.com/openxla/pjrt) (Pretty much Just another
RunTime), which allows you to *run* [XLA](https://openxla.org/) and
[stableHLO](https://openxla.org/stablehlo) programs on various hardware
backends. These programs are framework and hardware agnostic, which
means they can be generated by ML frameworks such as jax, and run by
PJRT on a specified backend (CPU, CUDA, etc.). For a low-level R
interface to *create* stableHLO programs, see the
[stablehlo](https://github.com/r-xla/stablehlo) package.

## Installation

``` r
pak::pak("r-xla/pjrt")
```

## Quickstart

The example below creates a stableHLO program that adds two float32
tensors of shape `(2, 2)`:

- `pjrt_program` creates a stableHLO program.
- `pjrt_client` creates a PJRT client which is the hardware backend for
  the specified platform (“cpu”, “cuda”, …).
- `pjrt_compile` compiles the program to an executable using the given
  client.
- `pjrt_buffer` creates a PJRT buffer (i.e. a tensors) from an R array.
- `pjrt_execute` runs the program.

``` r
library(pjrt)
src <- r"(
func.func @main(
  %x: tensor<2x2xf32>,
  %y: tensor<2x2xf32>
) -> tensor<2x2xf32> {
  %0 = "stablehlo.add"(%x, %y) : (tensor<2x2xf32>, tensor<2x2xf32>) -> tensor<2x2xf32>
  "func.return"(%0): (tensor<2x2xf32>) -> ()
}
)"
program <- pjrt_program(src, format = "mlir")
program
#> PJRTProgram(format=mlir, code_size=221)
#> 
#> func.func @main(
#>   %x: tensor<2x2xf32>,
#>   %y: tensor<2x2xf32>
#> ) -> tensor<2x2xf32> {
#> ...
executable <- pjrt_compile(program, client = pjrt_client("cpu"))

x <- matrix(as.double(1:4), nrow = 2)
y <- matrix(as.double(5:8), nrow = 2)
x_buffer <- pjrt_buffer(x, "f32")
y_buffer <- pjrt_buffer(y, "f32")

result <- pjrt_execute(executable, x_buffer, y_buffer)

as_array(result)
#>      [,1] [,2]
#> [1,]    6   10
#> [2,]    8   12
```

## Platform Support

- **Linux**
  - :white_check_mark: CPU backend is fully supported.
  - :white_check_mark: CUDA (NVIDIA GPU) backend is fully supported.
- **Windows**
  - :warning: Currently only supported via Windows Subsystem for Linux
    (WSL2).
- **macOS**
  - :white_check_mark: CPU backend is supported.
  - :warning: Metal (Apple GPU) backend is available but not fully
    functional.

## Acknowledgements

The design of the {pjrt} package was inspired by the
[gopjrt](https://github.com/gomlx/gopjrt) implementation.
