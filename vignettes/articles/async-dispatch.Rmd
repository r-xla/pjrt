---
title: "Asynchronous Dispatch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Asynchronous Dispatch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = pjrt::plugin_is_downloaded("cpu")
)
```

## The Problem: Host-Device Synchronization

When running computations on accelerators (GPUs, TPUs, or even optimized CPU backends), there's a fundamental tension between the **host** (R) and the **device** (accelerator). By default, every operation follows a synchronous pattern:

1. R sends data to the device
2. R waits for the transfer to complete

3. R tells the device to execute a computation
4. R waits for the computation to complete
5. R retrieves the result
6. R waits for the transfer to complete

This creates **synchronization bubbles**â€”periods where either the host or the device sits idle waiting for the other. In a training loop, these bubbles can significantly reduce throughput:

```
Host:   [prepare batch] [wait...] [prepare batch] [wait...] [prepare batch]
Device:        [wait...] [compute]        [wait...] [compute]        [wait...]
```

The ideal scenario overlaps host and device work:

```
Host:   [prepare batch 1] [prepare batch 2] [prepare batch 3] [prepare batch 4]
Device:          [compute 1] [compute 2] [compute 3] [compute 4]
```

## Asynchronous Dispatch in pjrt

The {pjrt} package provides async variants of key operations that return immediately, allowing R to continue while the device works in the background. These operations return **async value** objects that can be awaited later.

### The Async API

| Sync Operation | Async Operation | Returns |
|----------------|-----------------|---------|
| `pjrt_buffer()` | `pjrt_buffer_async()` | `pjrt_async_transfer` |
| `pjrt_execute()` | `pjrt_execute_async()` | `pjrt_async_value` |
| `as_array()` | `as_array_async()` | `pjrt_async_buffer` |

All async objects support:

- `value(x)` - Block until ready and return the result
- `is_ready(x)` - Check if complete (non-blocking)
- `as_array(x)` - Convert to R array (blocks if needed)

### Basic Example

```{r}
library(pjrt)

# Compile a simple program
src <- r"(
func.func @main(%x: tensor<1000x1000xf32>) -> tensor<1000x1000xf32> {
  %0 = "stablehlo.add"(%x, %x) : (tensor<1000x1000xf32>, tensor<1000x1000xf32>) -> tensor<1000x1000xf32>
  "func.return"(%0): (tensor<1000x1000xf32>) -> ()
}
)"
executable <- pjrt_compile(pjrt_program(src))
```

#### Synchronous execution (blocking)

```{r}
# Each step blocks until complete
data <- matrix(runif(1000 * 1000), nrow = 1000)
buf <- pjrt_buffer(data, dtype = "f32")       # Blocks: wait for transfer
result <- pjrt_execute(executable, buf)        # Blocks: wait for computation
output <- as_array(result)                     # Blocks: wait for transfer back
```

#### Asynchronous execution (non-blocking)

```{r}
# Operations return immediately
data <- matrix(runif(1000 * 1000), nrow = 1000)
transfer <- pjrt_buffer_async(data, dtype = "f32")  # Returns immediately
result <- pjrt_execute_async(executable, transfer)   # Returns immediately (auto-waits for transfer)
async_output <- as_array_async(result)               # Returns immediately

# R can do other work here while device computes...

# Only block when we actually need the value
output <- value(async_output)
```

## Smart Auto-Wait

A key feature of the async API is **smart auto-wait**. When you pass an async value as input to another operation, it automatically waits for only as long as necessary:

```{r}
# Start two async transfers in parallel
buf1 <- pjrt_buffer_async(matrix(1:4, 2, 2), dtype = "f32")
buf2 <- pjrt_buffer_async(matrix(5:8, 2, 2), dtype = "f32")

# Execute with async inputs - auto-waits internally
src2 <- r"(
func.func @main(%x: tensor<2x2xf32>, %y: tensor<2x2xf32>) -> tensor<2x2xf32> {
  %0 = "stablehlo.add"(%x, %y) : (tensor<2x2xf32>, tensor<2x2xf32>) -> tensor<2x2xf32>
  "func.return"(%0): (tensor<2x2xf32>) -> ()
}
)"
exec2 <- pjrt_compile(pjrt_program(src2))

# Pass async transfers directly - no explicit value() needed
result <- pjrt_execute_async(exec2, buf1, buf2)
as_array(result)
```

## When Blocking Happens

Understanding when R blocks is crucial for writing efficient code. Blocking occurs when:

1. **Calling `value()`** - Explicitly waiting for an async operation
2. **Calling `as_array()` on a buffer** - Transfers data from device to host
3. **Printing a buffer** - Needs to read values to display them
4. **Any operation that needs the actual data**

### Avoid Unnecessary Blocking

**Bad pattern** - Blocking in every iteration:

```r
for (i in seq_len(n_iterations)) {
  result <- pjrt_execute(executable, input)
  metrics <- as_array(result)  # BLOCKS! Device waits while we transfer
  cat("Step", i, "loss:", metrics[1], "\n")
  input <- prepare_next_batch()  # Device idle during data prep
}
```

**Better pattern** - Log previous iteration's metrics:

```r
prev_result <- NULL
for (i in seq_len(n_iterations)) {
  # Start this iteration's computation
  result <- pjrt_execute_async(executable, input)

  # While device computes, log PREVIOUS iteration's metrics
  if (!is.null(prev_result)) {
    metrics <- as_array(prev_result)  # Previous result likely ready
    cat("Step", i - 1, "loss:", metrics[1], "\n")
  }

  # Prepare next batch while device still computing
  input <- prepare_next_batch()
  prev_result <- result
}
```

## Checking Readiness

Use `is_ready()` for non-blocking status checks:

```{r}
# Start async operation
transfer <- pjrt_buffer_async(matrix(runif(1e6), 1000, 1000), dtype = "f32")

# Check without blocking
if (is_ready(transfer)) {
  message("Transfer complete!")
} else

  message("Still transferring...")
}

# Eventually get the value (blocks if needed)
buf <- value(transfer)
```

## Full Async Pipeline Example

Here's a complete example showing the full async pipeline:

```{r}
library(pjrt)

# Simple multiply-add program
src <- r"(
func.func @main(%x: tensor<100x100xf32>, %y: tensor<100x100xf32>) -> tensor<100x100xf32> {
  %0 = "stablehlo.multiply"(%x, %y) : (tensor<100x100xf32>, tensor<100x100xf32>) -> tensor<100x100xf32>
  %1 = "stablehlo.add"(%0, %x) : (tensor<100x100xf32>, tensor<100x100xf32>) -> tensor<100x100xf32>
  "func.return"(%1): (tensor<100x100xf32>) -> ()
}
)"
executable <- pjrt_compile(pjrt_program(src))

# Simulate a mini training loop
n_steps <- 5
shape <- c(100L, 100L)

# Initialize with async transfer
x <- pjrt_buffer_async(matrix(runif(prod(shape)), shape[1], shape[2]), dtype = "f32")
y <- pjrt_buffer_async(matrix(runif(prod(shape)), shape[1], shape[2]), dtype = "f32")

for (step in seq_len(n_steps)) {
  # Execute asynchronously (auto-waits for x and y if needed)
  result <- pjrt_execute_async(executable, x, y)

  # Use result as input to next iteration (chaining)
  x <- result

  # Only on last iteration, get the actual value
  if (step == n_steps) {
    final <- as_array(result)
    cat("Final result shape:", dim(final), "\n")
    cat("Final result[1,1]:", final[1, 1], "\n")
  }
}
```

## Summary

| Pattern | When to Use |
|---------|-------------|
| `pjrt_buffer()` | Simple scripts, when you need the buffer immediately |
| `pjrt_buffer_async()` | Training loops, when overlapping transfers with computation |
| `pjrt_execute()` | Simple inference, when you need results immediately |
| `pjrt_execute_async()` | Training loops, pipelining multiple operations |
| `as_array()` | When you need R values now |
| `as_array_async()` | When you want to overlap device-to-host transfer |

The key insight is that **blocking should happen as late as possible**. By using async operations and delaying `value()` calls, you allow the device to stay busy while R prepares the next batch of work.

## Further Reading

The concepts in this vignette are inspired by JAX's approach to asynchronous dispatch:

- [Asynchronous dispatch in JAX](https://docs.jax.dev/en/latest/async_dispatch.html)
- [The Training Cookbook: Efficiency via Asynchronous Dispatch](https://docs.jax.dev/en/latest/the-training-cookbook.html#efficiency-via-asynchronous-dispatch)
